{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Fuga de clientes</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../data/raw/train_clientes.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'ATTRITION'\n",
    "X, y = dataset.drop([target, 'ID_CORRELATIVO', 'CODMES'], axis=1), dataset[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "imputer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('mean_imputer', SimpleImputer(strategy='mean'), ['EDAD', 'ANTIGUEDAD']),\n",
    "        ('mode_imputer', SimpleImputer(strategy='most_frequent'), ['RANG_INGRESO', 'FLAG_LIMA_PROVINCIA']),\n",
    "        ('ohe', OneHotEncoder(categories='auto', drop='first', sparse_output=False, handle_unknown='error'), ['RANG_INGRESO','FLAG_LIMA_PROVINCIA','RANG_SDO_PASIVO_MENOS0','RANG_NRO_PRODUCTOS_MENOS0'])\n",
    "\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    ").set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['RANG_INGRESO', 'FLAG_LIMA_PROVINCIA'], axis=1, inplace=True)\n",
    "X_test.drop(['RANG_INGRESO', 'FLAG_LIMA_PROVINCIA'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "p:\\maestriaDS\\cursos\\c2-5-advancedSupervisedML\\env\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "p:\\maestriaDS\\cursos\\c2-5-advancedSupervisedML\\env\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8658, number of negative: 47342\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2581\n",
      "[LightGBM] [Info] Number of data points in the train set: 56000, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.154607 -> initscore=-1.698914\n",
      "[LightGBM] [Info] Start training from score -1.698914\n",
      "auc on training in LGBMClassifier data : 0.895\n",
      "auc on testing in LGBMClassifier  data : 0.851\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbmClassifier = LGBMClassifier() \n",
    "lgbmClassifier.fit(X_train, y_train)\n",
    "\n",
    "predict_train_lg = lgbmClassifier.predict_proba(X_train)[:,1]\n",
    "predict_test_lg = lgbmClassifier.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"auc on training in LGBMClassifier data : {:.3f}\".format(roc_auc_score(y_train, predict_train_lg)))\n",
    "print(\"auc on testing in LGBMClassifier  data : {:.3f}\".format(roc_auc_score(y_test, predict_test_lg))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc on training in LGBMClassifier data : 0.922\n",
      "auc on testing in LGBMClassifier  data : 0.850\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgbClassifier = XGBClassifier() \n",
    "xgbClassifier.fit(X_train, y_train)\n",
    "\n",
    "predict_train_lg = xgbClassifier.predict_proba(X_train)[:,1]\n",
    "predict_test_lg = xgbClassifier.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"auc on training in XGBClassifier data : {:.3f}\".format(roc_auc_score(y_train, predict_train_lg)))\n",
    "print(\"auc on testing in XGBClassifier  data : {:.3f}\".format(roc_auc_score(y_test, predict_test_lg))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc on training in CatBoostClassifier data : 0.911\n",
      "auc on testing in CatBoostClassifier  data : 0.855\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cbClassifier = CatBoostClassifier(verbose=0, n_estimators=500) \n",
    "cbClassifier.fit(X_train, y_train)\n",
    "\n",
    "predict_train_lg = cbClassifier.predict_proba(X_train)[:,1]\n",
    "predict_test_lg = cbClassifier.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"auc on training in CatBoostClassifier data : {:.3f}\".format(roc_auc_score(y_train, predict_train_lg)))\n",
    "print(\"auc on testing in CatBoostClassifier  data : {:.3f}\".format(roc_auc_score(y_test, predict_test_lg))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc on training in DecisionTreeClassifier data : 1.000\n",
      "auc on testing in DecisionTreeClassifier  data : 0.653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier(class_weight=None,\n",
    "                               criterion='gini',\n",
    "                               max_depth=None,\n",
    "                               max_features=None,\n",
    "                               max_leaf_nodes=None,\n",
    "                               min_samples_leaf=1,\n",
    "                               min_samples_split=2,\n",
    "                               min_weight_fraction_leaf=0.0,\n",
    "                               random_state=None,\n",
    "                               splitter='best')\n",
    "dtree.fit(X_train,y_train)\n",
    "\n",
    "predict_train_dtree = dtree.predict_proba(X_train)[:,1]\n",
    "predict_test_dtree = dtree.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"auc on training in DecisionTreeClassifier data : {:.3f}\".format(roc_auc_score(y_train, predict_train_dtree)))\n",
    "print(\"auc on testing in DecisionTreeClassifier  data : {:.3f}\".format(roc_auc_score(y_test, predict_test_dtree)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "p:\\maestriaDS\\cursos\\c2-5-advancedSupervisedML\\env\\Lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc on training in RandomForestClassifier data : 0.999\n",
      "auc on testing in RandomForestClassifier  data : 0.788\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(bootstrap=True,\n",
    "                            class_weight=None,\n",
    "                            criterion='gini',\n",
    "                            max_depth=None,\n",
    "                            max_features=None,\n",
    "                            max_leaf_nodes=None,\n",
    "                            min_samples_leaf=1,\n",
    "                            min_samples_split=2,\n",
    "                            min_weight_fraction_leaf=0.0,\n",
    "                            n_estimators=10,\n",
    "                            n_jobs=1,\n",
    "                            oob_score=False,\n",
    "                            random_state=None,\n",
    "                            verbose=0,\n",
    "                            warm_start=False\n",
    "                            )\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "predict_train_rfc = rfc.predict_proba(X_train)[:,1]\n",
    "predict_test_rfc = rfc.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"auc on training in RandomForestClassifier data : {:.3f}\".format(roc_auc_score(y_train, predict_train_rfc)))\n",
    "print(\"auc on testing in RandomForestClassifier  data : {:.3f}\".format(roc_auc_score(y_test, predict_test_rfc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "p:\\maestriaDS\\cursos\\c2-5-advancedSupervisedML\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc on training in LogisticRegression data : 0.708\n",
      "auc on testing in LogisticRegression  data : 0.695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "p:\\maestriaDS\\cursos\\c2-5-advancedSupervisedML\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predict_train_model = model.predict_proba(X_train)[:,1]\n",
    "predict_test_model = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"auc on training in LogisticRegression data : {:.3f}\".format(roc_auc_score(y_train, predict_train_model)))\n",
    "print(\"auc on testing in LogisticRegression  data : {:.3f}\".format(roc_auc_score(y_test, predict_test_model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "p:\\maestriaDS\\cursos\\c2-5-advancedSupervisedML\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc on training in LogisticRegression data : 0.665\n",
      "auc on testing in LogisticRegression  data : 0.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "p:\\maestriaDS\\cursos\\c2-5-advancedSupervisedML\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logmodel1 = LogisticRegression(C=1.0,\n",
    "                               class_weight=None,\n",
    "                               dual=False,\n",
    "                               fit_intercept=True,\n",
    "                               intercept_scaling=1,\n",
    "                               l1_ratio=None,\n",
    "                               max_iter=1000,\n",
    "                               multi_class='auto',\n",
    "                               n_jobs=None,\n",
    "                               penalty='l2',\n",
    "                               random_state=None,\n",
    "                               solver='lbfgs',\n",
    "                               tol=0.0001,\n",
    "                               verbose=0,\n",
    "                               warm_start=False\n",
    "                               )\n",
    "logmodel1.fit(X_train, y_train)\n",
    "\n",
    "predict_train_logmodel1 = logmodel1.predict_proba(X_train)[:,1]\n",
    "predict_test_logmodel1 = logmodel1.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"auc on training in LogisticRegression data : {:.3f}\".format(roc_auc_score(y_train, predict_train_logmodel1)))\n",
    "print(\"auc on testing in LogisticRegression  data : {:.3f}\".format(roc_auc_score(y_test, predict_test_logmodel1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
