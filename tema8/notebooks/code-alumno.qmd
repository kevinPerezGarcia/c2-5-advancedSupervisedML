---
title: Modelos Vía Ensamble para clasificación - MCD UNI
subtitle: Subtítulo
description: "Descripción del tema 8"
author:
    -   name: Kevin Pérez García
        url: https://kevinperezgarcia.quarto.pub/data-science-portfolio/
        affiliation: UNI - Maestría de Ciencia de Datos
        affiliation-url: https://fieecs.uni.edu.pe/maestriasupg/
title-block-banner: true
date: today
thanks: "A ti"
format:
    html:
        toc: true
        toc-float: true
        collapsed: false
        title-block-single: "Elaborado por"
        theme: readable
        highlight: kate
        code-summary: "Ver código"
        smooth-scroll: true
        link-external-newwindow: true
        citations-hover: true
        footnotes-hover: true
        warnings: false
lang: "es"
jupyter: python3
execute: 
    cache: true
    freeze: true
    echo: true
chalkboard: true
code-overflow: wrap
---

## Entendiendo los datos

### Importando librerías

```{python}
import pandas as pd
import numpy as np
```

Establemos una semilla para las cuestiones aleatorias:

```{python}
seed = 16
np.random.seed(seed)
```

### Cargando base de datos

```{python}
dataset = pd.read_csv('../data/raw/CreditScoring.csv')
dataset.head()
```

### Separando la base de datos

```{python}
X = dataset.drop('SeriousDlqin2yrs', axis=1)
y = dataset['SeriousDlqin2yrs']
```

### Dividiendo la base de datos

```{python}
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.25,
    stratify=y,
    random_state=1
)
```

## Preparación de los datos

Quitando variables innecesarias.

```{python}
for X in X_train, X_test:
    X.drop('ID', axis=1, inplace=True)
```

Imputando valores faltantes.

```{python}
MonthlyIncome_median_train = X_train['MonthlyIncome'].median()
NumberOfDependents_median_train = X_train['NumberOfDependents'].median()

for X in X_train, X_test:
    X['MonthlyIncome'] = X['MonthlyIncome'].fillna(MonthlyIncome_median_train)

    X['NumberOfDependents'] = X['NumberOfDependents'].fillna(NumberOfDependents_median_train)
```

## Preámbulo sobre la evaluación de los modelos

### Criterios de evaluación

Las métricas a evaluar son:

* accuracy_score
* precision_score
* recall_score
* entropy
* ROC-AUC

Las métricas a evaluar las obtendremos con la siguiente función.

```{python}
def get_metrics(y, y_pred, y_pred_proba):
    from sklearn.metrics import accuracy_score, precision_score, recall_score, log_loss, roc_auc_score
    accuracy = accuracy_score(y, y_pred)
    precision = precision_score(y, y_pred)
    recall = recall_score(y, y_pred)
    entropy = log_loss(y, y_pred_proba)
    roc_auc = roc_auc_score(y, y_pred_proba[:,1])
    return {'accuracy': round(accuracy, 2), 'precision': round(precision, 2), 'recall': round(recall, 2), 'entropy': round(entropy, 2), 'roc-auc': round(roc_auc, 2)}
```

### Definiendo funciones sobre predicción

La siguiente función permite obtener predicciones.

```{python}
def predict(model, X):
    y_pred = model.predict(X)
    return y_pred
```

La siguiente función permite obtener probabilidades de las predicciones.

```{python}
def predict_proba(model, X):
    y_pred_proba = model.predict_proba(X)
    return y_pred_proba
```

## Experimentación

Importando librerías:

```{python}
import mlflow
import mlflow.sklearn
```

Conectando la sesión de MLflow a Databricks CE:

```{python}
mlflow.set_tracking_uri("databricks")
```

### Regresión logística

```{python}
print("_____ Experimento: Regresión logística _____")

exp = mlflow.set_experiment(experiment_name="/logisticRegression")

print(f'Nombre del experimento: {exp.name}')
print(f'ID del experimento: {exp.experiment_id}')
```

```{python}
def track_model(run_name, penalty, class_weight):
    
    mlflow.start_run(run_name=run_name)

    run = mlflow.active_run()
    print(f'Nombre de la ejecución activa es: {run.info.run_name}')
    print(f'ID de la ejecución activa es: {run.info.run_id}')

    tags = {
        "Modelo": "Regresión Logística",
    }
    mlflow.set_tags(tags)

    # Entrenando el modelo:
    from sklearn.linear_model import LogisticRegression
    model = LogisticRegression(penalty=penalty, class_weight=class_weight)
    model.fit(X_train, y_train)

    mlflow.sklearn.log_model(model, "Regresión Logística")

    params = {
        'penalty': penalty,
        'class_weight': class_weight
    }
    mlflow.log_params(params)

    # Obteniendo predicciones:
    y_train_pred = predict(model, X_train)
    y_test_pred = predict(model, X_test)

    # Obteniendo probabilidades de las predicciones:
    y_train_pred_proba = predict_proba(model, X_train)
    y_test_pred_proba = predict_proba(model, X_test)

    # Obteniendo métricas:
    run_metrics_train = get_metrics(y_train, y_train_pred, y_train_pred_proba)
    run_metrics_test = get_metrics(y_test, y_test_pred, y_test_pred_proba)

    print(run_metrics_train)
    print(run_metrics_test)

    # Rastreando métricas sólo del conjunto de prueba
    for metric in run_metrics_test:
        mlflow.log_metric(metric, run_metrics_test[metric])

    mlflow.end_run()
```

```{python}
track_model(run_name="Base", penalty='l2', class_weight=None)
track_model(run_name="Base", penalty='l2', class_weight='balanced')
```

### Arbol de decisión

```{python}
print("_____ Primer experimento: Arbol de decisión _____")

exp = mlflow.set_experiment(experiment_name="/treeDecision")

print(f'Nombre del experimento: {exp.name}')
print(f'ID del experimento: {exp.experiment_id}')
```

```{python}
def track_model(run_name, max_depth, splitter):
    
    mlflow.start_run(run_name=run_name)

    run = mlflow.active_run()
    print(f'Nombre de la ejecución activa es: {run.info.run_name}')
    print(f'ID de la ejecución activa es: {run.info.run_id}')

    tags = {
        "Modelo": "Arbol de decisión",
    }
    mlflow.set_tags(tags)

    # Entrenando el modelo:
    from sklearn.tree import DecisionTreeClassifier
    model = DecisionTreeClassifier(max_depth=max_depth, splitter=splitter, random_state=2024)
    model.fit(X_train, y_train)

    mlflow.sklearn.log_model(model, "Arbol de decisión")

    params = {
        'max_depth': max_depth,
        'splitter': splitter
    }
    mlflow.log_params(params)

    # Obteniendo predicciones:
    y_train_pred = predict(model, X_train)
    y_test_pred = predict(model, X_test)

    # Obteniendo probabilidades de las predicciones:
    y_train_pred_proba = predict_proba(model, X_train)
    y_test_pred_proba = predict_proba(model, X_test)

    # Obteniendo métricas:
    run_metrics_train = get_metrics(y_train, y_train_pred, y_train_pred_proba)
    run_metrics_test = get_metrics(y_test, y_test_pred, y_test_pred_proba)

    print(run_metrics_train)
    print(run_metrics_test)

    # Rastreando métricas sólo del conjunto de prueba
    for metric in run_metrics_test:
        mlflow.log_metric(metric, run_metrics_test[metric])

    mlflow.end_run()
```

```{python}
track_model(run_name="Base", max_depth=3, splitter='best')
track_model(run_name="Base", max_depth=5, splitter='best')
track_model(run_name="Base", max_depth=7, splitter='best')
track_model(run_name="Base", max_depth=3, splitter='random')
track_model(run_name="Base", max_depth=5, splitter='random')
track_model(run_name="Base", max_depth=7, splitter='random')
```

### Red neuronal

```{python}
print("_____ Experimento: Red neuronal _____")

exp = mlflow.set_experiment(experiment_name="/neuralNetwork")

print(f'Nombre del experimento: {exp.name}')
print(f'ID del experimento: {exp.experiment_id}')
```

```{python}
def track_model(run_name, hidden_layer_sizes):
    
    mlflow.start_run(run_name=run_name)

    run = mlflow.active_run()
    print(f'Nombre de la ejecución activa es: {run.info.run_name}')
    print(f'ID de la ejecución activa es: {run.info.run_id}')

    tags = {
        "Modelo": "Red neuronal",
    }
    mlflow.set_tags(tags)

    # Entrenando el modelo:
    from sklearn.neural_network import MLPClassifier
    model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, random_state=2024)
    model.fit(X_train, y_train)

    mlflow.sklearn.log_model(model, "Red neuronal")

    params = {
        'hidden_layer_sizes': hidden_layer_sizes,
    }
    mlflow.log_params(params)

    # Obteniendo predicciones:
    y_train_pred = predict(model, X_train)
    y_test_pred = predict(model, X_test)

    # Obteniendo probabilidades de las predicciones:
    y_train_pred_proba = predict_proba(model, X_train)
    y_test_pred_proba = predict_proba(model, X_test)

    # Obteniendo métricas:
    run_metrics_train = get_metrics(y_train, y_train_pred, y_train_pred_proba)
    run_metrics_test = get_metrics(y_test, y_test_pred, y_test_pred_proba)

    print(run_metrics_train)
    print(run_metrics_test)

    # Rastreando métricas sólo del conjunto de prueba
    for metric in run_metrics_test:
        mlflow.log_metric(metric, run_metrics_test[metric])

    mlflow.end_run()
```

```{python}
track_model(run_name="hidden_layer_sizes=25", hidden_layer_sizes=25)
track_model(run_name="hidden_layer_sizes=50", hidden_layer_sizes=50)
track_model(run_name="hidden_layer_sizes=75", hidden_layer_sizes=75)
track_model(run_name="hidden_layer_sizes=100", hidden_layer_sizes=100)
```

### Random forest

```{python}
print("_____ Experimento: Random forest _____")

exp = mlflow.set_experiment(experiment_name="/randomForest")

print(f'Nombre del experimento: {exp.name}')
print(f'ID del experimento: {exp.experiment_id}')
```

```{python}
def track_model(run_name, n_estimators, max_depth):
    
    mlflow.start_run(run_name=run_name)

    run = mlflow.active_run()
    print(f'Nombre de la ejecución activa es: {run.info.run_name}')
    print(f'ID de la ejecución activa es: {run.info.run_id}')

    tags = {
        "Modelo": "Random forest",
    }
    mlflow.set_tags(tags)

    # Entrenando el modelo:
    from sklearn.ensemble import RandomForestClassifier
    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=2024)
    model.fit(X_train, y_train)

    mlflow.sklearn.log_model(model, "Random forest")

    params = {
        'n_estimators': n_estimators,
        'max_depth': max_depth
    }
    mlflow.log_params(params)

    # Obteniendo predicciones:
    y_train_pred = predict(model, X_train)
    y_test_pred = predict(model, X_test)

    # Obteniendo probabilidades de las predicciones:
    y_train_pred_proba = predict_proba(model, X_train)
    y_test_pred_proba = predict_proba(model, X_test)

    # Obteniendo métricas:
    run_metrics_train = get_metrics(y_train, y_train_pred, y_train_pred_proba)
    run_metrics_test = get_metrics(y_test, y_test_pred, y_test_pred_proba)

    print(run_metrics_train)
    print(run_metrics_test)

    # Rastreando métricas sólo del conjunto de prueba
    for metric in run_metrics_test:
        mlflow.log_metric(metric, run_metrics_test[metric])

    mlflow.end_run()
```

```{python}
track_model(run_name="n_estimators=25 & max_depth=5", n_estimators=25, max_depth=5)
track_model(run_name="n_estimators=25 & max_depth=10", n_estimators=50, max_depth=10)
track_model(run_name="n_estimators=25 & max_depth=5", n_estimators=25, max_depth=5)
track_model(run_name="n_estimators=25 & max_depth=10", n_estimators=50, max_depth=10)
```