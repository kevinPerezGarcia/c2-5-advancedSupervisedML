{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Biblioteca para manipulación y análisis de datos. Ideal para trabajar con tablas.\n",
    "import numpy as np  # Biblioteca para cálculos matemáticos complejos y manejo de arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../data/raw/data.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'ATTRITION'\n",
    "X, y = dataset.drop([target, 'ID_CORRELATIVO', 'CODMES'], axis=1), dataset[[target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,\n",
    "                                                   y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=1416,\n",
    "                                                   stratify=y\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = ColumnTransformer(\n",
    "    [\n",
    "        ('mean_imputer', SimpleImputer(strategy='mean'), ['EDAD', 'ANTIGUEDAD']),\n",
    "        ('mode_imputer', SimpleImputer(strategy='most_frequent'), ['RANG_INGRESO', 'FLAG_LIMA_PROVINCIA']),\n",
    "        #('ohe', OneHotEncoder(categories='auto', drop=None, sparse_output=False, handle_unknown='error'), ['RANG_INGRESO','FLAG_LIMA_PROVINCIA','RANG_SDO_PASIVO_MENOS0','RANG_NRO_PRODUCTOS_MENOS0'])\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    ").set_output(transform='pandas')\n",
    "\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = ColumnTransformer(\n",
    "    [\n",
    "        ('ohe', OneHotEncoder(categories='auto', drop=None, sparse_output=False, handle_unknown='error'), ['RANG_INGRESO','FLAG_LIMA_PROVINCIA','RANG_SDO_PASIVO_MENOS0','RANG_NRO_PRODUCTOS_MENOS0'])\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    ").set_output(transform='pandas')\n",
    "\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "X_test = encoder.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier  # Modelo de ensamblaje basado en árboles de decisión para tareas de clasificación.\n",
    "\n",
    "### Entreno un modelo de Random Forest con 200 arboles y una semilla aleatoria 123\n",
    "rf_clf = RandomForestClassifier(n_estimators=200,random_state =123)   ## forma del modelo\n",
    "\n",
    "# Entreno el modelo con el .fit\n",
    "rf_clf.fit(X_train.values,y_train.values.ravel())\n",
    "## ordenando  las mejores variables de mayor a menor generando un bucle en este caso un for para\n",
    "## extraer los nombres de las columnas y la ganancia(Gain) de las variables mas impactantes\n",
    "\n",
    "features = []\n",
    "for feature in zip(X.columns, rf_clf.feature_importances_):\n",
    "    features.append(feature)\n",
    "    \n",
    "## genero un dataframe para visualizar mejor lo que hizo random forest con su selector multivariado  \n",
    "features_total = pd.DataFrame(features,columns=['Variables','Gain']).sort_values('Gain', ascending=False)\n",
    "features_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selector de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel  # Selector de características basado en importancias derivadas de modelos.\n",
    "\n",
    "## uso SelectFromModel poniendo lo parametros del modelo que se contruyo y un threshold que es un punto de corte que\n",
    "## puede asumir de acuerdo a tu criterio con respecto a las variables que estén generando mas Gain\n",
    "\n",
    "sfm = SelectFromModel(rf_clf, threshold=0.008)\n",
    "\n",
    "# entrenamiento del selector\n",
    "sfm.fit(X, y)\n",
    "\n",
    "# contruyo una lista para quedarme con las mejores variables\n",
    "\n",
    "variables = [] #### lista vacía\n",
    "for feature_list_index in sfm.get_support(indices=True): ## \n",
    "    variables.append(X.columns[feature_list_index])\n",
    "    #variables\n",
    "    \n",
    "#features_total\n",
    "variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_X_train = X_train[variables]\n",
    "best_X_test  = X_test[variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score  # Funciones para calcular la precisión de clasificación y el área bajo la curva ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from lightgbm import LGBMClassifier  # Framework de boosting que utiliza algoritmos basados en árboles de decisión y es eficiente en grandes volúmenes de datos.\n",
    "\n",
    "# construimos un lightgbm, ojo que para elY es el mismo porque es un vector univariado\n",
    "best_model = LGBMClassifier() \n",
    "best_model.fit(best_X_train, y_train)\n",
    "\n",
    "\n",
    "# predecimos el train y test con la probabilidad para validar luego\n",
    "predict_train_lg = best_model.predict_proba(best_X_train)[:,1]\n",
    "predict_test_lg = best_model.predict_proba(best_X_test)[:,1]\n",
    "\n",
    "\n",
    "# imprimimos el roc de train y test con la data real y la prediccion de la probabilidad del modelo\n",
    "print(\"auc o Roc on training in LGBMClassifier data : {:.3f}\".format(roc_auc_score(y_train, predict_train_lg)))\n",
    "print(\"auc o Roc on testing in LGBMClassifier  data : {:.3f}\".format(roc_auc_score(y_test, predict_test_lg))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimización de hiperparámatros con validación cruzada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "# Mostramos todos los parametros que tiene ligthGBMlo usamos porque es mas rápido para tunear el modelo\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(best_model.get_params()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numero de arboles\n",
    "n_estimators = [300, 400, 500]\n",
    "# porcentaje de variables con la que se contruye un arbol\n",
    "colsample_bytree = [0.7, 0.8, 0.9]\n",
    "# profundidad del arbol\n",
    "max_depth = [4, 6, 8]\n",
    "# ratio de aprendizaje por cada arbol\n",
    "learning_rate = [0.1, 0.15 ,0.2]\n",
    "# creacion del grip search o grilla generando un diccionario\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'colsample_bytree': colsample_bytree,\n",
    "               'max_depth': max_depth,\n",
    "               'learning_rate': learning_rate}\n",
    "pprint(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV  # Herramientas para afinar hiperparámetros.\n",
    "\n",
    "lgb = LGBMClassifier()\n",
    "# Isntacia del grip search ponemos la grilla , la cantidad de kfolds para la validacion cruzada en este caso 5\n",
    "# n_jobs -1 para la paralelizacion de la ejecucion en la optimizacion del modelo y verbose para mostrar de 2 en 2 los resultados\n",
    "grid_search = GridSearchCV(estimator = lgb, param_grid = param_grid, cv = 5, n_jobs = -1, verbose = 2)\n",
    "# FIT para ejecutarlo\n",
    "X_best = X[variables] ## recordar que se usa toda la data completa y con las mejores variables\n",
    "grid_search.fit(X_best, y)\n",
    "grid_search.best_params_ # mostramos los mejores hiperparametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero una funcion para validar la mejora de la curva ROC o auc para ver como aumenta el performance de mi modelo\n",
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict_proba(test_features)[:,1] ## recordar que para validar el roc se necesita el dato real y \n",
    "    roc = roc_auc_score(test_labels,predictions)          ## probabilidad de la prediccion\n",
    "    print('Model Performance')\n",
    "    print('roc_auc_score = {:.12g}%.'.format(roc))\n",
    "    return roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = LGBMClassifier()\n",
    "base_model.fit(best_X_train, y_train)\n",
    "base_roc = evaluate(base_model, best_X_test, y_test)\n",
    "\n",
    "## pasamos la funcion evaluate para sacar el resultado del modelo\n",
    "best_grid = grid_search.best_estimator_\n",
    "grid_roc = evaluate(best_grid, best_X_test, y_test)\n",
    "print('Mejora en {:.12g}%.'.format( 100 * (grid_roc - base_roc) / base_roc)) ## le damos diseño para imprimir con .format\n",
    "## podemos visualizar el aumento o las mejora en 3.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "base_roc ## roc para el test  ---- modelo normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_roc ## roc para el test --- modelo optimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = LGBMClassifier()\n",
    "base_model.fit(best_X_train, y_train)\n",
    "base_roc = evaluate(base_model, best_X_train, y_train)\n",
    "\n",
    "## pasamos la funcion evaluate para sacar el resultado del modelo\n",
    "best_grid = grid_search.best_estimator_\n",
    "grid_roc = evaluate(best_grid, best_X_train, y_train)\n",
    "print('Mejora en {:.12g}%.'.format( 100 * (grid_roc - base_roc) / base_roc)) ## le damos diseño para imprimir con .format\n",
    "## podemos visualizar el aumento o las mejora en 3.5%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
