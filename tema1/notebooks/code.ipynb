{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>PRÁCTICA DIRIGIDA. COMPARACIÓN DEL RENDIMIENTO DE GENERALIZACIÓN DE MODELOS ESTADÍSTICOS Y DE MODELOS COMPUTACIONALES</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Teoría](#toc1_)    \n",
    "    - [Modelos Estadísticos](#toc1_1_1_)    \n",
    "    - [Modelos Computacionales](#toc1_1_2_)    \n",
    "    - [Comparación y Selección](#toc1_1_3_)    \n",
    "    - [Modelos Computacionales](#toc1_1_4_)    \n",
    "    - [Modelos Estadísticos](#toc1_1_5_)    \n",
    "- [Práctica. Fuga de clientes](#toc2_)    \n",
    "  - [Descripción del proyecto](#toc2_1_)    \n",
    "  - [Preprocesamiento](#toc2_2_)    \n",
    "  - [Procesamiento](#toc2_3_)    \n",
    "    - [Modelos estadísticos](#toc2_3_1_)    \n",
    "      - [Decision tree](#toc2_3_1_1_)    \n",
    "      - [Logistic regression](#toc2_3_1_2_)    \n",
    "    - [Modelos computacionales](#toc2_3_2_)    \n",
    "      - [LightGBM](#toc2_3_2_1_)    \n",
    "      - [XGBoost](#toc2_3_2_2_)    \n",
    "      - [Catboost](#toc2_3_2_3_)    \n",
    "      - [Random Forest](#toc2_3_2_4_)    \n",
    "- [Referencias](#toc3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Teoría](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI. (2023), ante la pregunta:\n",
    "\n",
    "\"Estoy realizando una práctica dirigida comparando el rendimiento de generalización de modelos computacionales y modelos estadístico. ¿cuáles son ambos tipos de modelos?\"\n",
    "\n",
    "En el ámbito de la investigación y la ciencia de datos, tanto los modelos computacionales como los estadísticos juegan roles fundamentales en la comprensión de datos y la generación de predicciones o inferencias sobre sistemas o fenómenos. Aunque ambos tipos de modelos buscan explicar o predecir comportamientos o patrones, sus enfoques y fundamentos pueden diferir significativamente.\n",
    "\n",
    "### <a id='toc1_1_1_'></a>[Modelos Estadísticos](#toc0_)\n",
    "\n",
    "Los modelos estadísticos son herramientas matemáticas que se utilizan para describir la relación entre variables. Están profundamente arraigados en la teoría de la probabilidad, permitiendo a los investigadores hacer inferencias o predicciones basadas en datos observacionales. Los modelos estadísticos pueden ser tanto descriptivos, sirviendo para resumir y describir las relaciones entre variables, como inferenciales, utilizados para hacer predicciones o testar hipótesis sobre la población a partir de la cual se recogieron los datos de muestra.\n",
    "\n",
    "Ejemplos de modelos estadísticos incluyen:\n",
    "\n",
    "- Regresión lineal y no lineal\n",
    "- Modelos de análisis de varianza (ANOVA)\n",
    "- Modelos de regresión logística\n",
    "- Modelos de series temporales, como ARIMA\n",
    "\n",
    "Estos modelos se caracterizan por sus suposiciones subyacentes sobre la distribución de los datos, la independencia de las observaciones, entre otros aspectos cruciales para su aplicación adecuada y la interpretación de sus resultados.\n",
    "\n",
    "### <a id='toc1_1_2_'></a>[Modelos Computacionales](#toc0_)\n",
    "\n",
    "Los modelos computacionales, por otro lado, pueden abarcar un espectro más amplio de técnicas que incluyen desde modelos basados en reglas hasta algoritmos de aprendizaje automático y redes neuronales profundas. Estos modelos no siempre se basan en la teoría estadística tradicional y a menudo son utilizados para capturar patrones complejos o para realizar tareas de predicción o clasificación donde las relaciones entre variables pueden ser no lineales, de alta dimensión y altamente interactivas.\n",
    "\n",
    "Ejemplos de modelos computacionales incluyen:\n",
    "\n",
    "- Redes neuronales artificiales\n",
    "- Máquinas de vector soporte\n",
    "- Algoritmos de clustering\n",
    "- Sistemas de recomendación\n",
    "- Modelos de procesamiento de lenguaje natural\n",
    "\n",
    "Los modelos computacionales suelen ser más flexibles en términos de las suposiciones sobre los datos, y en muchas situaciones, son capaces de manejar grandes volúmenes de datos (big data) y extraer patrones complejos que pueden no ser evidentes o accesibles a través de métodos estadísticos tradicionales.\n",
    "\n",
    "### <a id='toc1_1_3_'></a>[Comparación y Selección](#toc0_)\n",
    "\n",
    "La elección entre un modelo estadístico y uno computacional depende de varios factores, incluyendo:\n",
    "\n",
    "- La naturaleza y calidad de los datos disponibles.\n",
    "- El objetivo del análisis (e.g., explicación vs. predicción).\n",
    "- Los requisitos de interpretabilidad de los modelos.\n",
    "- Las limitaciones computacionales.\n",
    "\n",
    "Mientras que los modelos estadísticos ofrecen ventajas en términos de interpretación y comprensión teórica de las relaciones entre variables, los modelos computacionales pueden superar en rendimiento cuando se trata de manejar datos de gran volumen, complejidad y dimensionalidad, a pesar de que a menudo son considerados como \"cajas negras\" debido a su menor interpretabilidad.\n",
    "\n",
    "En resumen, tanto los modelos estadísticos como los computacionales tienen sus fortalezas y debilidades. La elección entre uno u otro debe guiarse por los objetivos específicos del estudio, las características de los datos y las necesidades de interpretación de los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI. (2023), ante la pregunta:\n",
    "\n",
    "\"De la siguiente lista:\n",
    "- LightGBM\n",
    "- XGBoost\n",
    "- Catboost\n",
    "- Decision tree\n",
    "- Random forest\n",
    "- Logistic regression\n",
    "¿cuáles son computacionales y estadísticos?\"\n",
    "\n",
    "De la lista proporcionada, podemos clasificar los modelos en \"computacionales\" y \"estadísticos\" basándonos en su enfoque y metodología subyacente, aunque esta clasificación puede ser algo fluida dado que todos los modelos se basan en principios matemáticos y estadísticos para realizar predicciones o clasificaciones. Sin embargo, se puede hacer una distinción basada en la complejidad, la capacidad de manejo de datos y la interpretabilidad de los modelos.\n",
    "\n",
    "### <a id='toc1_1_4_'></a>[Modelos Computacionales](#toc0_)\n",
    "\n",
    "Los modelos computacionales, en este contexto, se refieren a aquellos que suelen manejar grandes volúmenes de datos, pueden capturar relaciones no lineales complejas entre variables y son especialmente poderosos para tareas de predicción, aunque a menudo a costa de ser menos interpretables.\n",
    "\n",
    "- **LightGBM**: Es un framework de boosting que utiliza algoritmos basados en árboles de decisión y está optimizado para ser altamente eficiente en términos de velocidad y uso de memoria. Es computacional.\n",
    "- **XGBoost**: Otra implementación eficiente de gradient boosting que utiliza árboles de decisión y es conocido por su rendimiento en competiciones de machine learning. Es computacional.\n",
    "- **CatBoost**: Similar a los anteriores, es un algoritmo de boosting que utiliza árboles de decisión, optimizado para manejar variables categóricas de manera eficiente. Es computacional.\n",
    "- **Random Forest**: Un ensemble de árboles de decisión que mejora la precisión de las predicciones mediante el promedio de múltiples árboles de decisión entrenados en diferentes partes del conjunto de datos. Aunque usa técnicas estadísticas, generalmente se considera computacional debido a su enfoque de ensemble y su capacidad para manejar datos complejos.\n",
    "\n",
    "### <a id='toc1_1_5_'></a>[Modelos Estadísticos](#toc0_)\n",
    "\n",
    "Los modelos estadísticos, por otro lado, suelen enfocarse más en la interpretación de las relaciones entre variables y se basan más directamente en la teoría estadística.\n",
    "\n",
    "- **Decision Tree (Árbol de decisión)**: Aunque los árboles de decisión son la base de modelos computacionales más complejos (como Random Forest, XGBoost, etc.), un solo árbol de decisión puede ser visto como un modelo más estadístico debido a su simplicidad y alta interpretabilidad. Sin embargo, es importante notar que los árboles de decisión también se usan en contextos computacionales, lo que los hace un poco híbridos.\n",
    "- **Logistic Regression (Regresión logística)**: Este es un modelo estadístico clásico utilizado para predecir la probabilidad de una variable categórica binaria. Debido a su fundamento en la teoría estadística y su interpretabilidad, se clasifica claramente como un modelo estadístico.\n",
    "\n",
    "Es crucial entender que estas clasificaciones no son absolutas y que la distinción entre \"estadístico\" y \"computacional\" a menudo puede ser más una cuestión de cómo se aplica el modelo en la práctica. Los avances en las técnicas de machine learning están continuamente difuminando estas líneas, integrando aspectos de ambos enfoques para mejorar tanto la capacidad predictiva como la interpretabilidad de los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Práctica. Fuga de clientes](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[Descripción del proyecto](#toc0_)\n",
    "\n",
    "* Proyecto: Fuga de clientes\n",
    "* Machine learning: Supervisado\n",
    "* Categoría: Clasificación\n",
    "* Target: `ATTRITION`\n",
    "* Medida de desempeño: AUC\n",
    "* Algoritmos:\n",
    "  * Estadísticos:\n",
    "    * Random forest\n",
    "    * Logistic regression\n",
    "  * Computacionales:\n",
    "    * LightGBM\n",
    "    * XGBoost\n",
    "    * Catboost\n",
    "    * Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../data/raw/train_clientes.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'ATTRITION'\n",
    "X, y = dataset.drop([target, 'ID_CORRELATIVO', 'CODMES'], axis=1), dataset[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[Preprocesamiento](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "imputer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('mean_imputer', SimpleImputer(strategy='mean'), ['EDAD', 'ANTIGUEDAD']),\n",
    "        ('mode_imputer', SimpleImputer(strategy='most_frequent'), ['RANG_INGRESO', 'FLAG_LIMA_PROVINCIA']),\n",
    "        ('ohe', OneHotEncoder(categories='auto', drop='first', sparse_output=False, handle_unknown='error'), ['RANG_INGRESO','FLAG_LIMA_PROVINCIA','RANG_SDO_PASIVO_MENOS0','RANG_NRO_PRODUCTOS_MENOS0'])\n",
    "\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    ").set_output(transform='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['RANG_INGRESO', 'FLAG_LIMA_PROVINCIA'], axis=1, inplace=True)\n",
    "X_test.drop(['RANG_INGRESO', 'FLAG_LIMA_PROVINCIA'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[Procesamiento](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_3_1_'></a>[Modelos estadísticos](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_3_1_1_'></a>[Decision tree](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc on training in DecisionTreeClassifier data : 1.000\n",
      "auc on testing in DecisionTreeClassifier  data : 0.653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier(class_weight=None,\n",
    "                               criterion='gini',\n",
    "                               max_depth=None,\n",
    "                               max_features=None,\n",
    "                               max_leaf_nodes=None,\n",
    "                               min_samples_leaf=1,\n",
    "                               min_samples_split=2,\n",
    "                               min_weight_fraction_leaf=0.0,\n",
    "                               random_state=None,\n",
    "                               splitter='best')\n",
    "dtree.fit(X_train,y_train)\n",
    "\n",
    "predict_train_dtree = dtree.predict_proba(X_train)[:,1]\n",
    "predict_test_dtree = dtree.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"auc on training in DecisionTreeClassifier data : {:.3f}\".format(roc_auc_score(y_train, predict_train_dtree)))\n",
    "print(\"auc on testing in DecisionTreeClassifier  data : {:.3f}\".format(roc_auc_score(y_test, predict_test_dtree)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_3_1_2_'></a>[Logistic regression](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "p:\\maestriaDS\\cursos\\c2-5-advancedSupervisedML\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc on training in LogisticRegression data : 0.708\n",
      "auc on testing in LogisticRegression  data : 0.695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "p:\\maestriaDS\\cursos\\c2-5-advancedSupervisedML\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter=5000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predict_train_model = model.predict_proba(X_train)[:,1]\n",
    "predict_test_model = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"auc on training in LogisticRegression data : {:.3f}\".format(roc_auc_score(y_train, predict_train_model)))\n",
    "print(\"auc on testing in LogisticRegression  data : {:.3f}\".format(roc_auc_score(y_test, predict_test_model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "p:\\maestriaDS\\cursos\\c2-5-advancedSupervisedML\\env\\Lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc on training in LogisticRegression data : 0.665\n",
      "auc on testing in LogisticRegression  data : 0.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "p:\\maestriaDS\\cursos\\c2-5-advancedSupervisedML\\env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logmodel1 = LogisticRegression(C=1.0,\n",
    "                               class_weight=None,\n",
    "                               dual=False,\n",
    "                               fit_intercept=True,\n",
    "                               intercept_scaling=1,\n",
    "                               l1_ratio=None,\n",
    "                               max_iter=1000,\n",
    "                               multi_class='auto',\n",
    "                               n_jobs=None,\n",
    "                               penalty='l2',\n",
    "                               random_state=None,\n",
    "                               solver='lbfgs',\n",
    "                               tol=0.0001,\n",
    "                               verbose=0,\n",
    "                               warm_start=False\n",
    "                               )\n",
    "logmodel1.fit(X_train, y_train)\n",
    "\n",
    "predict_train_logmodel1 = logmodel1.predict_proba(X_train)[:,1]\n",
    "predict_test_logmodel1 = logmodel1.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"auc on training in LogisticRegression data : {:.3f}\".format(roc_auc_score(y_train, predict_train_logmodel1)))\n",
    "print(\"auc on testing in LogisticRegression  data : {:.3f}\".format(roc_auc_score(y_test, predict_test_logmodel1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_3_2_'></a>[Modelos computacionales](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_3_2_1_'></a>[LightGBM](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "p:\\maestriaDS\\cursos\\c2-5-advancedSupervisedML\\env\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "p:\\maestriaDS\\cursos\\c2-5-advancedSupervisedML\\env\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8658, number of negative: 47342\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2581\n",
      "[LightGBM] [Info] Number of data points in the train set: 56000, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.154607 -> initscore=-1.698914\n",
      "[LightGBM] [Info] Start training from score -1.698914\n",
      "auc on training in LGBMClassifier data : 0.895\n",
      "auc on testing in LGBMClassifier  data : 0.851\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbmClassifier = LGBMClassifier() \n",
    "lgbmClassifier.fit(X_train, y_train)\n",
    "\n",
    "predict_train_lg = lgbmClassifier.predict_proba(X_train)[:,1]\n",
    "predict_test_lg = lgbmClassifier.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"auc on training in LGBMClassifier data : {:.3f}\".format(roc_auc_score(y_train, predict_train_lg)))\n",
    "print(\"auc on testing in LGBMClassifier  data : {:.3f}\".format(roc_auc_score(y_test, predict_test_lg))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_3_2_2_'></a>[XGBoost](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc on training in LGBMClassifier data : 0.922\n",
      "auc on testing in LGBMClassifier  data : 0.850\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgbClassifier = XGBClassifier() \n",
    "xgbClassifier.fit(X_train, y_train)\n",
    "\n",
    "predict_train_lg = xgbClassifier.predict_proba(X_train)[:,1]\n",
    "predict_test_lg = xgbClassifier.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"auc on training in XGBClassifier data : {:.3f}\".format(roc_auc_score(y_train, predict_train_lg)))\n",
    "print(\"auc on testing in XGBClassifier  data : {:.3f}\".format(roc_auc_score(y_test, predict_test_lg))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_3_2_3_'></a>[Catboost](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc on training in CatBoostClassifier data : 0.911\n",
      "auc on testing in CatBoostClassifier  data : 0.855\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cbClassifier = CatBoostClassifier(verbose=0, n_estimators=500) \n",
    "cbClassifier.fit(X_train, y_train)\n",
    "\n",
    "predict_train_lg = cbClassifier.predict_proba(X_train)[:,1]\n",
    "predict_test_lg = cbClassifier.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"auc on training in CatBoostClassifier data : {:.3f}\".format(roc_auc_score(y_train, predict_train_lg)))\n",
    "print(\"auc on testing in CatBoostClassifier  data : {:.3f}\".format(roc_auc_score(y_test, predict_test_lg))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc2_3_2_4_'></a>[Random Forest](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "p:\\maestriaDS\\cursos\\c2-5-advancedSupervisedML\\env\\Lib\\site-packages\\sklearn\\base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc on training in RandomForestClassifier data : 0.999\n",
      "auc on testing in RandomForestClassifier  data : 0.788\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(bootstrap=True,\n",
    "                            class_weight=None,\n",
    "                            criterion='gini',\n",
    "                            max_depth=None,\n",
    "                            max_features=None,\n",
    "                            max_leaf_nodes=None,\n",
    "                            min_samples_leaf=1,\n",
    "                            min_samples_split=2,\n",
    "                            min_weight_fraction_leaf=0.0,\n",
    "                            n_estimators=10,\n",
    "                            n_jobs=1,\n",
    "                            oob_score=False,\n",
    "                            random_state=None,\n",
    "                            verbose=0,\n",
    "                            warm_start=False\n",
    "                            )\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "predict_train_rfc = rfc.predict_proba(X_train)[:,1]\n",
    "predict_test_rfc = rfc.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"auc on training in RandomForestClassifier data : {:.3f}\".format(roc_auc_score(y_train, predict_train_rfc)))\n",
    "print(\"auc on testing in RandomForestClassifier  data : {:.3f}\".format(roc_auc_score(y_test, predict_test_rfc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Referencias](#toc0_)\n",
    "\n",
    "OpenAI. (2023). ChatGPT (versión del 27 de marzo) [Modelo de lenguaje de gran tamaño]. https://chat.openai.com/chat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
